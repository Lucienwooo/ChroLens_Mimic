"""
é©—è­‰ç¢¼è­˜åˆ¥æ¨¡çµ„ - ä½¿ç”¨OCRæŠ€è¡“è­˜åˆ¥é©—è­‰ç¢¼
æ”¯æ´å¤šç¨®é©—è­‰ç¢¼é¡å‹ï¼šæ•¸å­—ã€å­—æ¯ã€æ··åˆ
âœ¨ é‡å° 76N8 å¼·å™ªé»é©—è­‰ç¢¼ç‰¹åˆ¥å„ªåŒ–
"""

import cv2
import numpy as np
from PIL import Image
import pyautogui
from typing import Optional, Tuple, List
import os
import math
from collections import Counter

try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    print("è­¦å‘Š: pytesseract æœªå®‰è£ï¼Œé©—è­‰ç¢¼è­˜åˆ¥åŠŸèƒ½å°‡å—é™")
    print("è«‹åŸ·è¡Œ: pip install pytesseract")
    print("ä¸¦ä¸‹è¼‰å®‰è£ Tesseract-OCR: https://github.com/tesseract-ocr/tesseract")


class CaptchaRecognizer:
    """é©—è­‰ç¢¼è­˜åˆ¥å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é©—è­‰ç¢¼è­˜åˆ¥å™¨"""
        self.tesseract_available = TESSERACT_AVAILABLE
        
        # å˜—è©¦è¨­å®š Tesseract è·¯å¾‘ (Windows)
        if TESSERACT_AVAILABLE:
            possible_paths = [
                r'C:\Program Files\Tesseract-OCR\tesseract.exe',
                r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
                r'D:\Program Files\Tesseract-OCR\tesseract.exe',
            ]
            for path in possible_paths:
                if os.path.exists(path):
                    pytesseract.pytesseract.tesseract_cmd = path
                    print(f"âœ“ æ‰¾åˆ° Tesseract: {path}")
                    break
    
    def capture_captcha(self, region: Tuple[int, int, int, int]) -> Optional[np.ndarray]:
        """
        æˆªå–é©—è­‰ç¢¼å€åŸŸ
        :param region: (left, top, width, height)
        :return: OpenCV åœ–ç‰‡é™£åˆ—
        """
        try:
            screenshot = pyautogui.screenshot(region=region)
            # è½‰æ›ç‚º OpenCV æ ¼å¼
            img_np = np.array(screenshot)
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
            return img_bgr
        except Exception as e:
            print(f"âœ— æˆªå–é©—è­‰ç¢¼å¤±æ•—: {e}")
            return None
    
    def preprocess_image(self, img: np.ndarray, method: str = "adaptive") -> np.ndarray:
        """
        åœ–ç‰‡é è™•ç† - æé«˜ OCR è­˜åˆ¥ç‡
        :param img: OpenCV åœ–ç‰‡
        :param method: é è™•ç†æ–¹æ³• ("adaptive", "otsu", "simple", "denoise", "strategy1-5")
        :return: è™•ç†å¾Œçš„åœ–ç‰‡
        """
        # 1. è½‰ç°éš
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()
        
        # ä½¿ç”¨å¼·åŒ–ç­–ç•¥è™•ç† 76N8 ç´šåˆ¥é©—è­‰ç¢¼
        if method == "strategy1":
            return self._strategy1_process(gray)
        elif method == "strategy2":
            return self._strategy2_process(gray)
        elif method == "strategy3":
            return self._strategy3_process(gray)
        elif method == "strategy4":
            return self._strategy4_process(gray)
        elif method == "strategy5":
            return self._strategy5_process(gray)
        elif method == "strategy6":
            return self._strategy6_process(gray)
        elif method == "strategy7":
            return self._strategy7_process(gray)
        elif method == "strategy8":
            return self._strategy8_process(gray)
        elif method == "strategy9" or method == "ultimate":
            return self._strategy9_ultimate_denoiser(gray)
        elif method == "strategy10" or method == "frequency":
            return self._strategy10_frequency_domain_killer(gray)
        
        # 2. æ”¾å¤§åœ–ç‰‡ (æé«˜è­˜åˆ¥ç‡)
        scale_factor = 3
        height, width = gray.shape
        enlarged = cv2.resize(gray, (width * scale_factor, height * scale_factor), 
                             interpolation=cv2.INTER_CUBIC)
        
        # 3. æ ¹æ“šæ–¹æ³•é€²è¡ŒäºŒå€¼åŒ–
        if method == "adaptive":
            # è‡ªé©æ‡‰é–¾å€¼ (é©åˆä¸å‡å‹»å…‰ç…§)
            binary = cv2.adaptiveThreshold(
                enlarged, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
        elif method == "otsu":
            # Otsu è‡ªå‹•é–¾å€¼
            _, binary = cv2.threshold(enlarged, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        elif method == "denoise":
            # é™å™ª + é–¾å€¼
            denoised = cv2.fastNlMeansDenoising(enlarged, None, 10, 7, 21)
            _, binary = cv2.threshold(denoised, 127, 255, cv2.THRESH_BINARY)
        else:  # simple
            # ç°¡å–®é–¾å€¼
            _, binary = cv2.threshold(enlarged, 127, 255, cv2.THRESH_BINARY)
        
        # 4. å½¢æ…‹å­¸æ“ä½œ - å»é™¤å™ªé»
        kernel = np.ones((2, 2), np.uint8)
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)
        
        return cleaned
    
    def _strategy1_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 1: è¶…å¼·æ”¾å¤§ + å¤šæ¬¡é™å™ª"""
        # è¶…å¼·æ”¾å¤§ 6 å€
        enlarged = cv2.resize(gray, None, fx=6, fy=6, interpolation=cv2.INTER_CUBIC)
        
        # å¤šé‡é™å™ª
        denoised = cv2.fastNlMeansDenoising(enlarged, None, h=15, templateWindowSize=7, searchWindowSize=21)
        
        # å½¢æ…‹å­¸æ¢¯åº¦
        kernel_edge = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        gradient = cv2.morphologyEx(denoised, cv2.MORPH_GRADIENT, kernel_edge)
        
        # Otsu äºŒå€¼åŒ–
        blurred = cv2.GaussianBlur(denoised, (5, 5), 0)
        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # é–‹é–‰é‹ç®—
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)
        
        # æ™ºèƒ½åè‰²
        if cv2.mean(closed)[0] > 127:
            cleaned = cv2.bitwise_not(closed)
        else:
            cleaned = closed
        
        # éŠ³åŒ–
        kernel_sharp = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])
        sharpened = cv2.filter2D(cleaned, -1, kernel_sharp)
        
        return sharpened
    
    def _strategy2_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 2: é›™é‚Šæ¿¾æ³¢ + CLAHE"""
        enlarged = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_CUBIC)
        
        # é›™é‚Šæ¿¾æ³¢
        bilateral = cv2.bilateralFilter(enlarged, 9, 75, 75)
        
        # CLAHE å°æ¯”åº¦å¢å¼·
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(bilateral)
        
        # è‡ªé©æ‡‰é–¾å€¼
        blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)
        adaptive = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                        cv2.THRESH_BINARY, 15, 3)
        
        # å½¢æ…‹å­¸
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        closed = cv2.morphologyEx(adaptive, cv2.MORPH_CLOSE, kernel, iterations=1)
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # åè‰²
        if cv2.mean(opened)[0] > 127:
            final = cv2.bitwise_not(opened)
        else:
            final = opened
        
        return final
    
    def _strategy3_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 3: é ‚å¸½è®Šæ›å»èƒŒæ™¯"""
        enlarged = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_CUBIC)
        
        # é ‚å¸½è®Šæ›
        kernel_tophat = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))
        tophat = cv2.morphologyEx(enlarged, cv2.MORPH_TOPHAT, kernel_tophat)
        blackhat = cv2.morphologyEx(enlarged, cv2.MORPH_BLACKHAT, kernel_tophat)
        
        processed = cv2.add(enlarged, tophat)
        processed = cv2.subtract(processed, blackhat)
        
        # å›ºå®šé–¾å€¼
        _, fixed_binary = cv2.threshold(processed, 127, 255, cv2.THRESH_BINARY)
        denoised = cv2.fastNlMeansDenoising(fixed_binary, None, 15, 7, 21)
        
        # åè‰²
        if cv2.mean(denoised)[0] > 127:
            denoised = cv2.bitwise_not(denoised)
        
        return denoised
    
    def _strategy4_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 4: Canny é‚Šç·£æª¢æ¸¬"""
        enlarged = cv2.resize(gray, None, fx=6, fy=6, interpolation=cv2.INTER_CUBIC)
        
        # é™å™ª
        denoised = cv2.fastNlMeansDenoising(enlarged, None, 20, 7, 21)
        
        # Canny é‚Šç·£
        blurred = cv2.GaussianBlur(denoised, (5, 5), 0)
        edges = cv2.Canny(blurred, 50, 150)
        
        # è†¨è„¹
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        dilated = cv2.dilate(edges, kernel_dilate, iterations=1)
        
        # éŠ³åŒ–
        kernel_sharpen = np.array([[-1,-1,-1,-1,-1],
                                   [-1, 2, 2, 2,-1],
                                   [-1, 2, 9, 2,-1],
                                   [-1, 2, 2, 2,-1],
                                   [-1,-1,-1,-1,-1]]) / 8.0
        sharpened = cv2.filter2D(dilated, -1, kernel_sharpen)
        
        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(sharpened, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        if cv2.mean(binary)[0] > 127:
            binary = cv2.bitwise_not(binary)
        
        return binary
    
    def _strategy5_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 5: å½¢æ…‹å­¸é‡å»º + è·é›¢è®Šæ› (76N8 å°ˆç”¨)"""
        # è¶…å¤§æ”¾å¤§ 8 å€
        enlarged = cv2.resize(gray, None, fx=8, fy=8, interpolation=cv2.INTER_CUBIC)
        
        # ä¸‰æ¬¡é™å™ª
        temp = cv2.fastNlMeansDenoising(enlarged, None, h=25, templateWindowSize=7, searchWindowSize=21)
        temp = cv2.fastNlMeansDenoising(temp, None, h=20, templateWindowSize=7, searchWindowSize=21)
        temp = cv2.fastNlMeansDenoising(temp, None, h=15, templateWindowSize=7, searchWindowSize=21)
        
        # å½¢æ…‹å­¸æ¢¯åº¦
        kernel_grad = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        gradient = cv2.morphologyEx(temp, cv2.MORPH_GRADIENT, kernel_grad)
        
        # çµ„åˆ
        combined = cv2.addWeighted(temp, 0.7, gradient, 0.3, 0)
        
        # Otsu äºŒå€¼åŒ–
        _, markers = cv2.threshold(combined, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # é–‹é–‰é‹ç®—
        kernel_final = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        opened = cv2.morphologyEx(markers, cv2.MORPH_OPEN, kernel_final, iterations=2)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel_final, iterations=1)
        
        # éŠ³åŒ–
        kernel_sharp5 = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
        final = cv2.filter2D(closed, -1, kernel_sharp5)
        
        # åè‰²
        if cv2.mean(final)[0] > 127:
            final = cv2.bitwise_not(final)
        
        return final
    
    def _strategy6_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 6: æ¥µè‡´é™å™ª + é€£é€šçµ„ä»¶åˆ†æ (å¼·å™ªé»å°ˆç”¨)"""
        # 10 å€è¶…å¤§æ”¾å¤§
        enlarged = cv2.resize(gray, None, fx=10, fy=10, interpolation=cv2.INTER_LANCZOS4)
        
        # å¤šéšæ®µé™å™ª
        # ç¬¬ä¸€éšæ®µï¼šä¸­å€¼æ¿¾æ³¢å»é™¤æ¤’é¹½å™ªé»
        median = cv2.medianBlur(enlarged, 5)
        
        # ç¬¬äºŒéšæ®µï¼šéå±€éƒ¨å‡å€¼é™å™ª
        denoised1 = cv2.fastNlMeansDenoising(median, None, h=30, templateWindowSize=7, searchWindowSize=21)
        
        # ç¬¬ä¸‰éšæ®µï¼šé«˜æ–¯é›™é‚Šæ¿¾æ³¢ï¼ˆä¿é‚Šå»å™ªï¼‰
        bilateral = cv2.bilateralFilter(denoised1, 11, 90, 90)
        
        # ç¬¬å››éšæ®µï¼šå†æ¬¡éå±€éƒ¨å‡å€¼
        denoised2 = cv2.fastNlMeansDenoising(bilateral, None, h=25, templateWindowSize=7, searchWindowSize=21)
        
        # CLAHE æ¥µè‡´å°æ¯”åº¦å¢å¼·
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(4,4))
        enhanced = clahe.apply(denoised2)
        
        # ä½¿ç”¨å¤šç¨®é–¾å€¼æ–¹æ³•çµ„åˆ
        # æ–¹æ³•1: Otsu
        _, binary1 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # æ–¹æ³•2: Triangle (é©åˆå™ªé»å¤šçš„åœ–ç‰‡)
        _, binary2 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)
        
        # çµ„åˆå…©ç¨®é–¾å€¼çµæœ
        combined = cv2.bitwise_and(binary1, binary2)
        
        # é€£é€šçµ„ä»¶åˆ†æå»é™¤å°å™ªé»
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(combined, connectivity=8)
        
        # è¨ˆç®—å¹³å‡é¢ç©
        if num_labels > 1:
            areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]
            avg_area = np.mean(areas) if areas else 0
            
            # å‰µå»ºé®ç½©ï¼Œåªä¿ç•™é¢ç©å¤§æ–¼å¹³å‡å€¼20%çš„çµ„ä»¶
            mask = np.zeros_like(combined)
            for i in range(1, num_labels):
                if stats[i, cv2.CC_STAT_AREA] > avg_area * 0.2:
                    mask[labels == i] = 255
        else:
            mask = combined
        
        # å½¢æ…‹å­¸é‡å»º
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        opened = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=3)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=2)
        
        # è¶…å¼·éŠ³åŒ–
        kernel_sharp = np.array([
            [0, -1, -1, -1, 0],
            [-1, 2, 2, 2, -1],
            [-1, 2, 13, 2, -1],
            [-1, 2, 2, 2, -1],
            [0, -1, -1, -1, 0]
        ]) / 5.0
        sharpened = cv2.filter2D(closed, -1, kernel_sharp)
        
        # åè‰²
        if cv2.mean(sharpened)[0] > 127:
            final = cv2.bitwise_not(sharpened)
        else:
            final = sharpened
        
        return final
    
    def _strategy7_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 7: é »åŸŸæ¿¾æ³¢ + è‡ªé©æ‡‰å±€éƒ¨é–¾å€¼ (å™ªé»å…‹æ˜Ÿ)"""
        # 8 å€æ”¾å¤§
        enlarged = cv2.resize(gray, None, fx=8, fy=8, interpolation=cv2.INTER_CUBIC)
        
        # é »åŸŸæ¿¾æ³¢å»é™¤å‘¨æœŸæ€§å™ªé»
        # è½‰æ›åˆ°é »åŸŸ
        dft = cv2.dft(np.float32(enlarged), flags=cv2.DFT_COMPLEX_OUTPUT)
        dft_shift = np.fft.fftshift(dft)
        
        # å‰µå»ºå¸¶é€šæ¿¾æ³¢å™¨ï¼ˆå»é™¤é«˜é »å™ªé»å’Œä½é »èƒŒæ™¯ï¼‰
        rows, cols = enlarged.shape
        crow, ccol = rows // 2, cols // 2
        mask = np.ones((rows, cols, 2), np.uint8)
        
        # å»é™¤ä½é »ï¼ˆèƒŒæ™¯ï¼‰
        r_low = 30
        center = [crow, ccol]
        x, y = np.ogrid[:rows, :cols]
        mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r_low*r_low
        mask[mask_area] = 0
        
        # å»é™¤éé«˜é »ï¼ˆå™ªé»ï¼‰
        r_high = min(rows, cols) // 4
        mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 >= r_high*r_high
        mask[mask_area] = 0
        
        # æ‡‰ç”¨æ¿¾æ³¢å™¨
        fshift = dft_shift * mask
        
        # é€†è®Šæ›å›ç©ºåŸŸ
        f_ishift = np.fft.ifftshift(fshift)
        img_back = cv2.idft(f_ishift)
        img_back = cv2.magnitude(img_back[:,:,0], img_back[:,:,1])
        
        # æ­¸ä¸€åŒ–
        img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
        
        # éå±€éƒ¨å‡å€¼é™å™ª
        denoised = cv2.fastNlMeansDenoising(img_back, None, h=20, templateWindowSize=7, searchWindowSize=21)
        
        # è‡ªé©æ‡‰å±€éƒ¨é–¾å€¼ï¼ˆé‡å°ä¸å‡å‹»å…‰ç…§ï¼‰
        # ä½¿ç”¨è¼ƒå¤§çš„ block size ä¾†é©æ‡‰å­—ç¬¦å¤§å°
        adaptive = cv2.adaptiveThreshold(
            denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, blockSize=25, C=8
        )
        
        # å½¢æ…‹å­¸é–‰é‹ç®—é€£æ¥æ–·è£‚ç­†ç•«
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        closed = cv2.morphologyEx(adaptive, cv2.MORPH_CLOSE, kernel_close, iterations=2)
        
        # é–‹é‹ç®—å»é™¤å°å™ªé»
        kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open, iterations=1)
        
        # åè‰²
        if cv2.mean(opened)[0] > 127:
            final = cv2.bitwise_not(opened)
        else:
            final = opened
        
        return final
    
    def _strategy8_process(self, gray: np.ndarray) -> np.ndarray:
        """ç­–ç•¥ 8: å¤šå°ºåº¦è™•ç† + æŠ•ç¥¨æ©Ÿåˆ¶ (çµ‚æ¥µç©©å®šç‰ˆ)"""
        results = []
        
        # å¤šå°ºåº¦è™•ç†ï¼ˆ5x, 7x, 9xï¼‰
        for scale in [5, 7, 9]:
            enlarged = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
            
            # é™å™ª
            denoised = cv2.fastNlMeansDenoising(enlarged, None, h=20, templateWindowSize=7, searchWindowSize=21)
            
            # ä½¿ç”¨å¤šç¨®äºŒå€¼åŒ–æ–¹æ³•
            # Otsu
            _, binary1 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # è‡ªé©æ‡‰
            binary2 = cv2.adaptiveThreshold(
                denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, blockSize=21, C=5
            )
            
            # Triangle
            _, binary3 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)
            
            # æŠ•ç¥¨æ©Ÿåˆ¶ï¼šè‡³å°‘2ç¨®æ–¹æ³•èªç‚ºæ˜¯å‰æ™¯æ‰ç®—å‰æ™¯
            vote = (binary1.astype(np.float32) + binary2.astype(np.float32) + binary3.astype(np.float32)) / 3.0
            voted = (vote > 127).astype(np.uint8) * 255
            
            results.append(voted)
        
        # å°‡ä¸‰å€‹å°ºåº¦çš„çµæœèª¿æ•´ç‚ºç›¸åŒå¤§å°ï¼ˆä½¿ç”¨ä¸­é–“å°ºåº¦ï¼‰
        target_size = results[1].shape[::-1]
        results[0] = cv2.resize(results[0], target_size, interpolation=cv2.INTER_AREA)
        results[2] = cv2.resize(results[2], target_size, interpolation=cv2.INTER_AREA)
        
        # å¤šå°ºåº¦æŠ•ç¥¨
        final_vote = (results[0].astype(np.float32) + results[1].astype(np.float32) + results[2].astype(np.float32)) / 3.0
        final = (final_vote > 127).astype(np.uint8) * 255
        
        # å½¢æ…‹å­¸ç²¾ç…‰
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        final = cv2.morphologyEx(final, cv2.MORPH_CLOSE, kernel, iterations=1)
        final = cv2.morphologyEx(final, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # åè‰²
        if cv2.mean(final)[0] > 127:
            final = cv2.bitwise_not(final)
        
        return final
    
    def _strategy9_ultimate_denoiser(self, gray: np.ndarray) -> np.ndarray:
        """
        ç­–ç•¥ 9: çµ‚æ¥µå™ªé»æ®ºæ‰‹ - å°ˆé–€é‡å° 76N8 ç´šåˆ¥çš„å¼·å™ªé» ğŸ”¥
        æ¡ç”¨å¤šéšæ®µæ¼¸é€²å¼è™•ç†ï¼šé è™•ç† â†’ æ¥µè‡´é™å™ª â†’ æ™ºèƒ½å¢å¼· â†’ ç²¾æº–äºŒå€¼åŒ– â†’ å¾Œè™•ç†å„ªåŒ–
        """
        print("    ğŸ”¥ å•Ÿå‹•çµ‚æ¥µå™ªé»æ®ºæ‰‹æ¨¡å¼...")
        
        # ===== ç¬¬ä¸€éšæ®µï¼šé è™•ç† - å»ºç«‹è‰¯å¥½åŸºç¤ =====
        # è¶…å¤§æ”¾å¤§ 12 å€ï¼ˆæä¾›æ›´å¤šç´°ç¯€ç”¨æ–¼é™å™ªï¼‰
        h, w = gray.shape
        enlarged = cv2.resize(gray, (w * 12, h * 12), interpolation=cv2.INTER_LANCZOS4)
        
        # ===== ç¬¬äºŒéšæ®µï¼šæ¥µè‡´é™å™ª - å¤šå±¤éæ¿¾ =====
        # éšæ®µ 2.1: å½¢æ…‹å­¸é–‰é‹ç®—é å¡«å……ï¼ˆæ¸›å°‘å™ªé»å­”æ´ï¼‰
        kernel_pre = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        morphed = cv2.morphologyEx(enlarged, cv2.MORPH_CLOSE, kernel_pre, iterations=2)
        
        # éšæ®µ 2.2: ä¸­å€¼æ¿¾æ³¢ï¼ˆæ¶ˆé™¤æ¤’é¹½å™ªé»ï¼‰
        median1 = cv2.medianBlur(morphed, 7)
        
        # éšæ®µ 2.3: éå±€éƒ¨å‡å€¼é™å™ªï¼ˆç¬¬ä¸€æ¬¡ï¼Œh=35 å¼·åŠ›å»å™ªï¼‰
        nlm1 = cv2.fastNlMeansDenoising(median1, None, h=35, templateWindowSize=9, searchWindowSize=25)
        
        # éšæ®µ 2.4: é›™é‚Šæ¿¾æ³¢ï¼ˆä¿é‚Šå¼·åŒ–ï¼‰
        bilateral = cv2.bilateralFilter(nlm1, 15, 100, 100)
        
        # éšæ®µ 2.5: é«˜æ–¯æ¿¾æ³¢ï¼ˆå¹³æ»‘éæ¸¡ï¼‰
        gaussian = cv2.GaussianBlur(bilateral, (7, 7), 1.5)
        
        # éšæ®µ 2.6: éå±€éƒ¨å‡å€¼é™å™ªï¼ˆç¬¬äºŒæ¬¡ï¼Œh=25 ç²¾ç´°èª¿æ•´ï¼‰
        nlm2 = cv2.fastNlMeansDenoising(gaussian, None, h=25, templateWindowSize=9, searchWindowSize=21)
        
        # ===== ç¬¬ä¸‰éšæ®µï¼šæ™ºèƒ½å¢å¼· - å‡¸é¡¯å­—ç¬¦ç‰¹å¾µ =====
        # éšæ®µ 3.1: è¶…å¼· CLAHE å°æ¯”åº¦å¢å¼·
        clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(3, 3))
        enhanced = clahe.apply(nlm2)
        
        # éšæ®µ 3.2: éŠ³åŒ–æ¿¾æ³¢ï¼ˆå¢å¼·é‚Šç·£ï¼‰
        kernel_sharpen = np.array([
            [-1, -1, -1, -1, -1],
            [-1,  2,  2,  2, -1],
            [-1,  2, 16,  2, -1],
            [-1,  2,  2,  2, -1],
            [-1, -1, -1, -1, -1]
        ]) / 8.0
        sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)
        
        # éšæ®µ 3.3: å½¢æ…‹å­¸æ¢¯åº¦ï¼ˆçªå‡ºé‚Šç•Œï¼‰
        kernel_grad = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        gradient = cv2.morphologyEx(sharpened, cv2.MORPH_GRADIENT, kernel_grad)
        
        # éšæ®µ 3.4: æ··åˆå¢å¼·ï¼ˆ70% éŠ³åŒ– + 30% æ¢¯åº¦ï¼‰
        mixed = cv2.addWeighted(sharpened, 0.7, gradient, 0.3, 0)
        
        # ===== ç¬¬å››éšæ®µï¼šç²¾æº–äºŒå€¼åŒ– - å¤šæ–¹æ³•æŠ•ç¥¨ =====
        # å†æ¬¡é™å™ªå¾Œé€²è¡ŒäºŒå€¼åŒ–
        final_denoise = cv2.fastNlMeansDenoising(mixed, None, h=20, templateWindowSize=7, searchWindowSize=21)
        
        # æ–¹æ³• 1: Otsu å…¨å±€é–¾å€¼
        _, binary_otsu = cv2.threshold(final_denoise, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # æ–¹æ³• 2: Triangle é–¾å€¼ï¼ˆé©åˆåæ…‹åˆ†ä½ˆï¼‰
        _, binary_triangle = cv2.threshold(final_denoise, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)
        
        # æ–¹æ³• 3: è‡ªé©æ‡‰é–¾å€¼ï¼ˆå±€éƒ¨èª¿æ•´ï¼‰
        binary_adaptive = cv2.adaptiveThreshold(
            final_denoise, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, blockSize=31, C=10
        )
        
        # æ–¹æ³• 4: åŸºæ–¼å‡å€¼çš„é–¾å€¼
        mean_val = cv2.mean(final_denoise)[0]
        _, binary_mean = cv2.threshold(final_denoise, mean_val * 0.9, 255, cv2.THRESH_BINARY)
        
        # å››æ–¹æ³•åŠ æ¬ŠæŠ•ç¥¨ï¼ˆOtsu æ¬Šé‡æœ€é«˜ï¼‰
        vote = (
            binary_otsu.astype(np.float32) * 0.35 +
            binary_triangle.astype(np.float32) * 0.25 +
            binary_adaptive.astype(np.float32) * 0.25 +
            binary_mean.astype(np.float32) * 0.15
        ) / 255.0
        
        # è¶…é 50% æŠ•ç¥¨æ‰èªç‚ºæ˜¯å‰æ™¯
        voted = (vote > 0.5).astype(np.uint8) * 255
        
        # ===== ç¬¬äº”éšæ®µï¼šå¾Œè™•ç†å„ªåŒ– - ç§»é™¤æ®˜ç•™å™ªé» =====
        # éšæ®µ 5.1: é€£é€šçµ„ä»¶åˆ†æï¼ˆç§»é™¤å°å™ªé»ï¼‰
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(voted, connectivity=8)
        
        cleaned = np.zeros_like(voted)
        if num_labels > 1:
            # è¨ˆç®—é¢ç©çµ±è¨ˆ
            areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]
            if areas:
                median_area = np.median(areas)
                # åªä¿ç•™é¢ç© > ä¸­ä½æ•¸çš„ 15% çš„çµ„ä»¶
                for i in range(1, num_labels):
                    area = stats[i, cv2.CC_STAT_AREA]
                    if area > median_area * 0.15:
                        cleaned[labels == i] = 255
        else:
            cleaned = voted
        
        # éšæ®µ 5.2: å½¢æ…‹å­¸é–‰é‹ç®—ï¼ˆé€£æ¥æ–·è£‚ç­†ç•«ï¼‰
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4, 4))
        closed = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel_close, iterations=3)
        
        # éšæ®µ 5.3: å½¢æ…‹å­¸é–‹é‹ç®—ï¼ˆå»é™¤ç´°å°æ¯›åˆºï¼‰
        kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open, iterations=2)
        
        # éšæ®µ 5.4: å†æ¬¡éŠ³åŒ–ï¼ˆæå‡æ¸…æ™°åº¦ï¼‰
        kernel_final_sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
        final_sharpened = cv2.filter2D(opened, -1, kernel_final_sharp)
        
        # éšæ®µ 5.5: æ™ºèƒ½åè‰²åˆ¤æ–·
        mean_brightness = cv2.mean(final_sharpened)[0]
        if mean_brightness > 127:
            result = cv2.bitwise_not(final_sharpened)
        else:
            result = final_sharpened
        
        print("    âœ… çµ‚æ¥µé™å™ªå®Œæˆ")
        return result
    
    def _strategy10_frequency_domain_killer(self, gray: np.ndarray) -> np.ndarray:
        """
        ç­–ç•¥ 10: é »åŸŸå™ªé»æ®ºæ‰‹ - ä½¿ç”¨å‚…ç«‹è‘‰è®Šæ›åœ¨é »åŸŸç²¾æº–å»é™¤å‘¨æœŸæ€§å™ªé»
        """
        print("    âš¡ å•Ÿå‹•é »åŸŸå™ªé»æ®ºæ‰‹...")
        
        # æ”¾å¤§ 10 å€
        enlarged = cv2.resize(gray, None, fx=10, fy=10, interpolation=cv2.INTER_LANCZOS4)
        
        # é é™å™ª
        denoised = cv2.fastNlMeansDenoising(enlarged, None, h=25, templateWindowSize=7, searchWindowSize=21)
        
        # è½‰æ›åˆ°é »åŸŸ
        dft = cv2.dft(np.float32(denoised), flags=cv2.DFT_COMPLEX_OUTPUT)
        dft_shift = np.fft.fftshift(dft)
        
        # å‰µå»ºç²¾ç´°å¸¶é€šæ¿¾æ³¢å™¨
        rows, cols = denoised.shape
        crow, ccol = rows // 2, cols // 2
        
        # å‰µå»ºé®ç½©
        mask = np.ones((rows, cols, 2), np.float32)
        
        # è¨ˆç®—è·é›¢çŸ©é™£
        y, x = np.ogrid[:rows, :cols]
        dist = np.sqrt((x - ccol)**2 + (y - crow)**2)
        
        # ç§»é™¤ä½é »ï¼ˆèƒŒæ™¯ï¼‰- åŠå¾‘ 40
        mask[dist < 40] = 0
        
        # ç§»é™¤é«˜é »ï¼ˆå™ªé»ï¼‰- ä¿ç•™ä¸­é »ï¼ˆå­—ç¬¦é‚Šç·£ï¼‰
        r_high = min(rows, cols) // 5
        mask[dist > r_high] = 0.3  # ä¸å®Œå…¨ç§»é™¤ï¼Œä¿ç•™ 30%
        
        # å°ç‰¹å®šé »ç‡åŠ å¼·è¡°æ¸›ï¼ˆé‡å°å‘¨æœŸæ€§å™ªé»ï¼‰
        # æª¢æ¸¬ä¸¦æŠ‘åˆ¶èƒ½é‡å³°å€¼
        magnitude = np.sqrt(dft_shift[:,:,0]**2 + dft_shift[:,:,1]**2)
        threshold = np.percentile(magnitude, 98)  # å‰ 2% çš„èƒ½é‡
        high_energy_mask = magnitude > threshold
        mask[high_energy_mask] *= 0.1  # å¼·çƒˆæŠ‘åˆ¶é«˜èƒ½é‡é»
        
        # æ‡‰ç”¨æ¿¾æ³¢å™¨
        fshift = dft_shift * mask
        
        # é€†è®Šæ›å›ç©ºåŸŸ
        f_ishift = np.fft.ifftshift(fshift)
        img_back = cv2.idft(f_ishift)
        img_back = cv2.magnitude(img_back[:,:,0], img_back[:,:,1])
        
        # æ­¸ä¸€åŒ–
        img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
        
        # å¾Œè™•ç†
        # é›™é‚Šæ¿¾æ³¢
        bilateral = cv2.bilateralFilter(img_back, 11, 80, 80)
        
        # CLAHE
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(4, 4))
        enhanced = clahe.apply(bilateral)
        
        # å¤šé–¾å€¼æŠ•ç¥¨
        _, b1 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        b2 = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY, 27, 8)
        
        # æŠ•ç¥¨
        voted = ((b1.astype(np.float32) + b2.astype(np.float32)) / 2.0 > 127).astype(np.uint8) * 255
        
        # å½¢æ…‹å­¸
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        result = cv2.morphologyEx(voted, cv2.MORPH_CLOSE, kernel, iterations=2)
        result = cv2.morphologyEx(result, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # åè‰²
        if cv2.mean(result)[0] > 127:
            result = cv2.bitwise_not(result)
        
        print("    âœ… é »åŸŸè™•ç†å®Œæˆ")
        return result
    
    def recognize_with_tesseract(self, img: np.ndarray, 
                                 char_type: str = "alphanumeric") -> Optional[str]:
        """
        ä½¿ç”¨ Tesseract OCR è­˜åˆ¥é©—è­‰ç¢¼
        :param img: OpenCV åœ–ç‰‡
        :param char_type: å­—ç¬¦é¡å‹ ("digits", "alpha", "alphanumeric")
        :return: è­˜åˆ¥å‡ºçš„æ–‡å­—
        """
        if not self.tesseract_available:
            print("âœ— Tesseract ä¸å¯ç”¨ï¼Œè«‹å®‰è£ pytesseract å’Œ Tesseract-OCR")
            return None
        
        try:
            # è¨­å®š Tesseract é…ç½®
            if char_type == "digits":
                config = '--psm 7 -c tessedit_char_whitelist=0123456789'
            elif char_type == "alpha":
                config = '--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
            else:  # alphanumeric
                config = '--psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
            
            # è½‰æ›ç‚º PIL Image
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(img_rgb)
            
            # åŸ·è¡Œ OCR
            text = pytesseract.image_to_string(pil_img, config=config)
            text = text.strip()
            
            return text if text else None
            
        except Exception as e:
            print(f"âœ— Tesseract è­˜åˆ¥å¤±æ•—: {e}")
            return None
    
    def recognize_captcha(self, 
                         region: Tuple[int, int, int, int],
                         char_type: str = "alphanumeric",
                         try_all_methods: bool = True,
                         use_enhanced_strategies: bool = True) -> Optional[str]:
        """
        å®Œæ•´é©—è­‰ç¢¼è­˜åˆ¥æµç¨‹
        :param region: é©—è­‰ç¢¼å€åŸŸ (left, top, width, height)
        :param char_type: å­—ç¬¦é¡å‹ ("digits", "alpha", "alphanumeric")
        :param try_all_methods: æ˜¯å¦å˜—è©¦æ‰€æœ‰é è™•ç†æ–¹æ³•
        :param use_enhanced_strategies: æ˜¯å¦ä½¿ç”¨å¢å¼·ç­–ç•¥ (76N8 ç´šåˆ¥)
        :return: è­˜åˆ¥å‡ºçš„é©—è­‰ç¢¼
        """
        print("\n" + "="*50)
        print("ğŸ” é–‹å§‹é©—è­‰ç¢¼è­˜åˆ¥æµç¨‹")
        if use_enhanced_strategies:
            print("ğŸš€ å·²å•Ÿç”¨å¢å¼·ç­–ç•¥ (76N8 ç´šåˆ¥)")
        print("="*50)
        
        # 1. æˆªå–é©—è­‰ç¢¼
        print(f"[1/4] æˆªå–é©—è­‰ç¢¼å€åŸŸ: {region}")
        img = self.capture_captcha(region)
        if img is None:
            return None
        print("  âœ“ æˆªå–æˆåŠŸ")
        
        # 2. å˜—è©¦ä¸åŒçš„é è™•ç†æ–¹æ³•
        print(f"[2/4] åœ–ç‰‡é è™•ç†...")
        
        # æ ¹æ“šæ˜¯å¦å•Ÿç”¨å¢å¼·ç­–ç•¥é¸æ“‡æ–¹æ³•
        if use_enhanced_strategies:
            # ğŸ”¥ æ–°å¢å…©å€‹çµ‚æ¥µç­–ç•¥ï¼Œå„ªå…ˆä½¿ç”¨
            methods = [
                "strategy9",    # çµ‚æ¥µå™ªé»æ®ºæ‰‹ï¼ˆæœ€å¼·ï¼‰
                "strategy10",   # é »åŸŸå™ªé»æ®ºæ‰‹
                "strategy6",    # æ¥µè‡´é™å™ª + é€£é€šçµ„ä»¶
                "strategy7",    # é »åŸŸæ¿¾æ³¢ + è‡ªé©æ‡‰
                "strategy8",    # å¤šå°ºåº¦æŠ•ç¥¨
                "strategy5",    # å½¢æ…‹å­¸é‡å»º
                "strategy1",    # è¶…å¼·æ”¾å¤§é™å™ª
                "strategy2",    # é›™é‚Šæ¿¾æ³¢ CLAHE
            ]
            psm_modes = [6, 7, 8, 10, 11, 13]  # ä½¿ç”¨æ›´å¤š PSM æ¨¡å¼
        elif try_all_methods:
            methods = ["adaptive", "otsu", "denoise", "simple"]
            psm_modes = [7]  # é è¨­å–®è¡Œæ–‡å­—
        else:
            methods = ["adaptive"]
            psm_modes = [7]
        
        all_results = []
        
        for method in methods:
            print(f"  â†’ å˜—è©¦æ–¹æ³•: {method}")
            processed = self.preprocess_image(img, method)
            
            # 3. OCR è­˜åˆ¥ - å˜—è©¦å¤šå€‹ PSM æ¨¡å¼
            for psm in psm_modes:
                result = self.recognize_with_tesseract_psm(processed, char_type, psm)
                
                if result and len(result) >= 3:  # éæ¿¾å¤ªçŸ­çš„çµæœ
                    all_results.append((result, f"{method}-PSM{psm}"))
                    print(f"    PSM {psm}: '{result}'")
        
        # 4. çµ±è¨ˆå’Œé¸æ“‡æœ€ä½³çµæœ
        print(f"[3/4] åˆ†æçµæœ...")
        if all_results:
            from collections import Counter
            
            # çµ±è¨ˆå‡ºç¾æ¬¡æ•¸
            result_counts = Counter([r for r, _ in all_results])
            
            # é¡¯ç¤ºæ‰€æœ‰çµæœ
            print(f"  æœ‰æ•ˆçµæœå…± {len(all_results)} å€‹:")
            for result, count in result_counts.most_common(5):
                sources = [s for r, s in all_results if r == result]
                print(f"    '{result}' å‡ºç¾ {count} æ¬¡")
            
            # é¸æ“‡æœ€ä½³çµæœ
            most_common = result_counts.most_common(1)[0]
            if most_common[1] > 1:  # å¦‚æœæœ‰çµæœå‡ºç¾å¤šæ¬¡
                best_result = most_common[0]
            else:
                # é¸æ“‡æœ€é•·çš„çµæœ
                best_result = max(all_results, key=lambda x: len(x[0]))[0]
            
            print(f"[4/4] å®Œæˆ")
            print(f"âœ“ æœ€çµ‚çµæœ: '{best_result}' (é•·åº¦: {len(best_result)})")
            print("="*50 + "\n")
            return best_result
        else:
            print(f"[4/4] å®Œæˆ")
            print(f"âœ— æ‰€æœ‰æ–¹æ³•å‡ç„¡æ³•è­˜åˆ¥é©—è­‰ç¢¼")
            print("="*50 + "\n")
            return None
    
    def recognize_with_tesseract_psm(self, img: np.ndarray, 
                                    char_type: str = "alphanumeric",
                                    psm: int = 7) -> Optional[str]:
        """
        ä½¿ç”¨æŒ‡å®š PSM æ¨¡å¼çš„ Tesseract OCR è­˜åˆ¥
        :param img: OpenCV åœ–ç‰‡
        :param char_type: å­—ç¬¦é¡å‹ ("digits", "alpha", "alphanumeric")
        :param psm: Page Segmentation Mode (0-13)
        :return: è­˜åˆ¥å‡ºçš„æ–‡å­—
        """
        if not self.tesseract_available:
            return None
        
        try:
            # è¨­å®š Tesseract é…ç½®
            if char_type == "digits":
                whitelist = '0123456789'
            elif char_type == "alpha":
                whitelist = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
            else:  # alphanumeric
                whitelist = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
            
            config = f'--psm {psm} --oem 3 -c tessedit_char_whitelist={whitelist}'
            
            # è½‰æ›ç‚º PIL Image
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(img_rgb)
            
            # åŸ·è¡Œ OCR
            text = pytesseract.image_to_string(pil_img, config=config)
            # åªä¿ç•™å­—æ¯å’Œæ•¸å­—
            text = ''.join(filter(str.isalnum, text)).strip()
            
            return text if text else None
            
        except Exception as e:
            return None
    
    def save_debug_image(self, img: np.ndarray, filename: str = "captcha_debug.png"):
        """
        å„²å­˜é™¤éŒ¯åœ–ç‰‡
        :param img: OpenCV åœ–ç‰‡
        :param filename: æª”æ¡ˆåç¨±
        """
        try:
            cv2.imwrite(filename, img)
            print(f"âœ“ é™¤éŒ¯åœ–ç‰‡å·²å„²å­˜: {filename}")
        except Exception as e:
            print(f"âœ— å„²å­˜é™¤éŒ¯åœ–ç‰‡å¤±æ•—: {e}")


class SimpleCaptchaRecognizer:
    """
    ç°¡å–®é©—è­‰ç¢¼è­˜åˆ¥å™¨ - ä¸éœ€è¦ Tesseract
    é©ç”¨æ–¼ç°¡å–®çš„æ•¸å­—æˆ–å­—æ¯é©—è­‰ç¢¼
    ä½¿ç”¨æ¨¡æ¿åŒ¹é…æ–¹æ³•
    """
    
    def __init__(self, template_dir: str = "captcha_templates"):
        """
        åˆå§‹åŒ–
        :param template_dir: å­—ç¬¦æ¨¡æ¿è³‡æ–™å¤¾
        """
        self.template_dir = template_dir
        self.templates = {}
        self.load_templates()
    
    def load_templates(self):
        """è¼‰å…¥å­—ç¬¦æ¨¡æ¿"""
        if not os.path.exists(self.template_dir):
            print(f"è­¦å‘Š: æ¨¡æ¿è³‡æ–™å¤¾ä¸å­˜åœ¨: {self.template_dir}")
            return
        
        for filename in os.listdir(self.template_dir):
            if filename.endswith(('.png', '.jpg', '.jpeg')):
                # æª”åæ‡‰ç‚ºå­—ç¬¦æœ¬èº« (ä¾‹: 0.png, A.png)
                char = os.path.splitext(filename)[0]
                template_path = os.path.join(self.template_dir, filename)
                template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)
                if template is not None:
                    self.templates[char] = template
        
        print(f"âœ“ å·²è¼‰å…¥ {len(self.templates)} å€‹å­—ç¬¦æ¨¡æ¿")
    
    def segment_characters(self, img: np.ndarray) -> List[np.ndarray]:
        """
        åˆ‡å‰²å­—ç¬¦
        :param img: äºŒå€¼åŒ–åœ–ç‰‡
        :return: å­—ç¬¦åœ–ç‰‡åˆ—è¡¨
        """
        # å°‹æ‰¾è¼ªå»“
        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # æ ¹æ“š x åº§æ¨™æ’åº
        bounding_boxes = [cv2.boundingRect(c) for c in contours]
        bounding_boxes = sorted(bounding_boxes, key=lambda x: x[0])
        
        # æå–å­—ç¬¦
        characters = []
        for x, y, w, h in bounding_boxes:
            # éæ¿¾å¤ªå°çš„å€åŸŸ (å¯èƒ½æ˜¯å™ªé»)
            if w > 5 and h > 5:
                char_img = img[y:y+h, x:x+w]
                characters.append(char_img)
        
        return characters
    
    def match_character(self, char_img: np.ndarray, threshold: float = 0.7) -> Optional[str]:
        """
        åŒ¹é…å–®ä¸€å­—ç¬¦
        :param char_img: å­—ç¬¦åœ–ç‰‡
        :param threshold: åŒ¹é…é–¾å€¼
        :return: è­˜åˆ¥å‡ºçš„å­—ç¬¦
        """
        best_match = None
        best_score = 0
        
        for char, template in self.templates.items():
            # èª¿æ•´å¤§å°ä»¥åŒ¹é…æ¨¡æ¿
            resized = cv2.resize(char_img, (template.shape[1], template.shape[0]))
            
            # æ¨¡æ¿åŒ¹é…
            result = cv2.matchTemplate(resized, template, cv2.TM_CCOEFF_NORMED)
            _, max_val, _, _ = cv2.minMaxLoc(result)
            
            if max_val > best_score:
                best_score = max_val
                best_match = char
        
        if best_score >= threshold:
            return best_match
        return None
    
    def recognize_captcha(self, img: np.ndarray) -> Optional[str]:
        """
        è­˜åˆ¥é©—è­‰ç¢¼
        :param img: OpenCV åœ–ç‰‡
        :return: è­˜åˆ¥çµæœ
        """
        # é è™•ç†
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
        
        # åˆ‡å‰²å­—ç¬¦
        characters = self.segment_characters(binary)
        
        if not characters:
            return None
        
        # è­˜åˆ¥æ¯å€‹å­—ç¬¦
        result = ""
        for char_img in characters:
            char = self.match_character(char_img)
            if char:
                result += char
        
        return result if result else None


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    print("é©—è­‰ç¢¼è­˜åˆ¥æ¨¡çµ„æ¸¬è©¦")
    print("="*50)
    
    # æ¸¬è©¦ 1: ä½¿ç”¨ Tesseract
    if TESSERACT_AVAILABLE:
        print("\næ¸¬è©¦ Tesseract OCR:")
        recognizer = CaptchaRecognizer()
        
        # è«‹æä¾›é©—è­‰ç¢¼å€åŸŸåº§æ¨™
        # region = (x, y, width, height)
        # result = recognizer.recognize_captcha(region, char_type="digits")
        # print(f"è­˜åˆ¥çµæœ: {result}")
    
    # æ¸¬è©¦ 2: ç°¡å–®æ¨¡æ¿åŒ¹é…
    print("\næ¸¬è©¦æ¨¡æ¿åŒ¹é…:")
    simple_recognizer = SimpleCaptchaRecognizer()
    print(f"å·²è¼‰å…¥ {len(simple_recognizer.templates)} å€‹æ¨¡æ¿")
